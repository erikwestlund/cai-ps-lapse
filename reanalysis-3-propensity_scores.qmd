---
title: "Reanalysis Step 3: Propensity Score Analysis with Twang"
subtitle: "Calculating IPTW weights using GBM across imputed datasets"
author: "Erik Westlund"
date: "`r Sys.Date()`"
format: html
---

## Setup

```{r setup}
#| include: false
# Setup analysis environment
source("dependencies.R")
setup_analysis(seed = 2025)

# Additional packages
library(twang)
library(survey)
library(cobalt)
library(ggplot2)
library(gridExtra)
library(knitr)

# ANALYSIS MODE: Use same as imputation
analysis_mode <- "test"  # Should match imputation mode

# Set parameters based on mode
if (analysis_mode == "test") {
  max_imputations_for_diagnostics <- 2  # Show diagnostics for 2 imputations in test
  n_trees <- 1000  # Fewer trees for testing
} else {
  max_imputations_for_diagnostics <- 5  # Show diagnostics for up to 5 imputations in final
  n_trees <- 3000  # More trees for final analysis
}

message("Analysis mode: ", analysis_mode)
message("Will show diagnostics for up to ", max_imputations_for_diagnostics, " imputations")
message("Using ", n_trees, " trees for GBM")
```

## Load Imputed Datasets

```{r load-data}
# Load the imputed datasets
imputed_datasets <- readRDS(file.path(reanalysis_data_dir, "imputed_datasets.rds"))
n_imputations <- length(imputed_datasets)

message("Loaded ", n_imputations, " imputed datasets")

# Load variable lists
variable_lists <- readRDS(file.path(reanalysis_data_dir, "variable_lists.rds"))
```

## Define Enhanced Propensity Score Formula

```{r ps-formula}
# Original formula from get_matching_formula()
# Now enhanced to include DR severity and treatment type

# Create enhanced formula including person_dr and treatment interactions
ps_formula_enhanced <- as.formula("ever_lapse_binary ~ 
  baseline_VA_logMAR +
  gender_cat +
  race_ethnic_cat +
  insurance_cat +
  age_cat +
  CCI +
  DCSI +
  other_inject +
  anti_VEGF +
  focal_laser_flag +
  PRP_flag +
  glaucoma_bef_hitplus_cat +
  otherretina_bef_hitplus_cat +
  catsurg_before_hitplus_cat +
  person_dr +  # Added DR severity
  treatment_type  # Added treatment type
")

message("Propensity score formula:")
print(ps_formula_enhanced)

# Alternative: Use the standard formula from functions.R
ps_formula_standard <- get_matching_formula()

# For this analysis, we'll use the enhanced formula
ps_formula <- ps_formula_enhanced
```

## Run Twang Propensity Score Models

Following the approach in twang-analysis.Rmd, we'll use GBM via twang package to estimate propensity scores.

```{r ps-models}
# Initialize storage for PS results
twang_results <- list()

# Run twang for each imputed dataset
message("\nCalculating propensity scores using Twang GBM...")
message("Parameters:")
message("  - n.trees: ", n_trees)
message("  - interaction.depth: 3")
message("  - shrinkage: 0.01")
message("  - estimand: ATT")
message("  - stop.method: es.mean (effect size only)")

for (i in 1:n_imputations) {
  message("\nProcessing imputation ", i, " of ", n_imputations, "...")
  
  # Run twang ps model with es.mean only
  twang_model <- ps(
    formula = ps_formula,
    data = imputed_datasets[[i]],
    n.trees = n_trees,
    interaction.depth = 3,
    shrinkage = 0.01,
    estimand = "ATT",
    stop.method = "es.mean",  # Only use es.mean for faster computation
    n.minobsinnode = 10,
    verbose = FALSE
  )
  
  # Extract weights for ATT
  weights <- get.weights(twang_model, stop.method = "es.mean")
  
  # Store results
  # When using single stop method, ps is a vector not a matrix
  ps_scores <- if(is.matrix(twang_model$ps)) {
    twang_model$ps[, "es.mean"]
  } else {
    twang_model$ps  # Already a vector when single stop method
  }
  
  # Get balance table from summary
  balance_table <- tryCatch({
    sum_obj <- summary(twang_model)
    # Extract the balance table for es.mean
    if (!is.null(sum_obj$es.mean.ATT)) {
      sum_obj$es.mean.ATT
    } else if (!is.null(sum_obj$es.mean)) {
      sum_obj$es.mean
    } else {
      NULL
    }
  }, error = function(e) {
    NULL
  })
  
  twang_results[[i]] <- list(
    model = twang_model,
    weights = weights,
    ps_scores = ps_scores,
    n_trees_used = twang_model$desc$es.mean$n.trees,
    balance_es_mean = balance_table
  )
  
  message("  - Trees used (es.mean): ", twang_model$desc$es.mean$n.trees)
}

message("\nTwang propensity score calculation complete")
```

## Balance Assessment

```{r balance-assessment}
# Extract balance summaries from twang models
balance_summaries <- list()

for (i in 1:n_imputations) {
  # Get the twang model
  twang_model <- twang_results[[i]]$model
  
  # Get balance table from the summary
  # When using es.mean only, the balance table is in summary()$es.mean.ATT
  bal_table <- tryCatch({
    # Get the summary and extract balance table
    sum_obj <- summary(twang_model)
    # For single stop method, look for es.mean.ATT
    if (!is.null(sum_obj$es.mean.ATT)) {
      sum_obj$es.mean.ATT
    } else if (!is.null(sum_obj$es.mean)) {
      sum_obj$es.mean
    } else if (!is.null(sum_obj[[1]])) {
      # Sometimes it's the first element
      sum_obj[[1]]
    } else {
      NULL
    }
  }, error = function(e) {
    NULL
  })
  
  if (!is.null(bal_table)) {
    # The balance table from bal.table has a specific structure
    # Usually columns like: tx.mn, tx.sd, ct.mn, ct.sd, std.eff.sz, stat, p, ks, ks.pval
    
    # Look for standardized effect size columns
    es_values <- if ("std.eff.sz" %in% names(bal_table)) {
      abs(bal_table$std.eff.sz)
    } else if ("std.es" %in% names(bal_table)) {
      abs(bal_table$std.es)
    } else if ("es" %in% names(bal_table)) {
      abs(bal_table$es)
    } else {
      # Calculate manually from means and SDs if available
      if (all(c("tx.mn", "ct.mn") %in% names(bal_table))) {
        tx_means <- bal_table$tx.mn
        ct_means <- bal_table$ct.mn
        # Use tx.sd if available, otherwise assume 1
        pooled_sd <- if ("tx.sd" %in% names(bal_table)) {
          bal_table$tx.sd
        } else {
          rep(1, length(tx_means))
        }
        abs((tx_means - ct_means) / pooled_sd)
      } else {
        rep(NA, nrow(bal_table))
      }
    }
    
    # Look for KS statistics
    ks_values <- if ("ks" %in% names(bal_table)) {
      bal_table$ks
    } else if ("ks.max" %in% names(bal_table)) {
      bal_table$ks.max  
    } else {
      rep(NA, length(es_values))
    }
    
    # Create summary
    balance_summaries[[i]] <- data.frame(
      Imputation = i,
      Mean_ES = mean(es_values, na.rm = TRUE),
      Max_ES = max(es_values, na.rm = TRUE),
      N_Imbalanced = sum(es_values > 0.1, na.rm = TRUE),
      Mean_KS = mean(ks_values, na.rm = TRUE),
      Max_KS = max(ks_values, na.rm = TRUE)
    )
  } else {
    # If we can't get balance table, use a simpler approach
    # Just check if weights improve balance by looking at correlations
    weights <- twang_results[[i]]$weights
    treated <- imputed_datasets[[i]]$ever_lapse_binary == 1
    
    balance_summaries[[i]] <- data.frame(
      Imputation = i,
      Mean_ES = NA,
      Max_ES = NA, 
      N_Imbalanced = NA,
      Mean_KS = NA,
      Max_KS = NA
    )
    message("Note: Using simplified balance assessment for imputation ", i)
  }
}

# Combine all summaries
balance_summary_all <- do.call(rbind, balance_summaries)

# Calculate average across imputations
avg_balance <- data.frame(
  Mean_ES = mean(balance_summary_all$Mean_ES),
  Max_ES = mean(balance_summary_all$Max_ES),
  N_Imbalanced = mean(balance_summary_all$N_Imbalanced),
  Mean_KS = mean(balance_summary_all$Mean_KS),
  Max_KS = mean(balance_summary_all$Max_KS)
)

message("\nBalance Summary Across All Imputations:")
kable(balance_summary_all, 
      caption = "Balance metrics by imputation",
      digits = 3)

message("\nAverage Balance Across Imputations:")
kable(avg_balance,
      caption = "Average balance metrics across all imputations",
      digits = 3)

# Check if balance is acceptable
if (avg_balance$Max_ES > 0.25) {
  message("\n⚠ Warning: Maximum effect size > 0.25, indicating potential residual imbalance")
} else if (avg_balance$Max_ES > 0.1) {
  message("\nNote: Some covariates have effect size > 0.1")
} else {
  message("\n✓ Excellent balance achieved (all effect sizes < 0.1)")
}
```

## Diagnostics for Sample of Imputations

```{r diagnostics-plots}
#| fig-height: 8
#| fig-width: 10

# Select imputations to show diagnostics for
n_to_show <- min(max_imputations_for_diagnostics, n_imputations)
imps_to_show <- 1:n_to_show

message("\nGenerating twang diagnostic plots for ", n_to_show, " imputations...")

# For each selected imputation, show twang-specific diagnostics
for (i in imps_to_show) {
  message("\nDiagnostics for Imputation ", i, ":")
  
  # Get the twang model for this imputation
  twang_model <- twang_results[[i]]$model
  
  # Try to generate diagnostic plots
  tryCatch({
    # The standard twang plots
    plot(twang_model)
  }, error = function(e) {
    message("  Standard plots not available, generating custom diagnostics...")
    
    # Create custom diagnostic plots
    ps_scores <- twang_results[[i]]$ps_scores
    weights <- twang_results[[i]]$weights
    treated <- imputed_datasets[[i]]$ever_lapse_binary == 1
    
    par(mfrow = c(2, 2))
    
    # Plot 1: PS distribution by treatment
    hist(ps_scores[!treated], main = "PS Distribution - Control", 
         xlab = "Propensity Score", col = "lightblue")
    hist(ps_scores[treated], main = "PS Distribution - Treated", 
         xlab = "Propensity Score", col = "lightcoral")
    
    # Plot 2: Weight distribution
    hist(weights[!treated], main = "Weights - Control", 
         xlab = "Weight", col = "lightblue")
    hist(weights[treated], main = "Weights - Treated", 
         xlab = "Weight", col = "lightcoral")
    
    par(mfrow = c(1, 1))
  })
  
  # Print summary
  print(summary(twang_model))
}
```

## Propensity Score Distribution

```{r ps-distribution}
#| fig-height: 8
#| fig-width: 12

# Plot PS distribution for first few imputations
for (i in imps_to_show) {
  message("\nPropensity score distributions for imputation ", i)
  
  # Create data for plotting
  plot_data <- data.frame(
    ps = twang_results[[i]]$ps_scores,
    treatment = factor(imputed_datasets[[i]]$ever_lapse_binary,
                      levels = c(0, 1),
                      labels = c("Control", "Treated"))
  )
  
  # Histogram of propensity scores by treatment group
  p1 <- ggplot(plot_data, aes(x = ps, fill = treatment)) +
    geom_histogram(alpha = 0.6, position = "identity", bins = 30) +
    labs(title = paste("Twang GBM Propensity Scores - Imputation", i),
         x = "Propensity Score",
         y = "Count") +
    theme_minimal() +
    scale_fill_manual(values = c("blue", "red")) +
    facet_wrap(~ treatment, ncol = 1, scales = "free_y")
  
  # Density plot overlay
  p2 <- ggplot(plot_data, aes(x = ps, color = treatment, fill = treatment)) +
    geom_density(alpha = 0.3) +
    labs(title = paste("Density of Propensity Scores - Imputation", i),
         x = "Propensity Score",
         y = "Density") +
    theme_minimal() +
    scale_fill_manual(values = c("blue", "red")) +
    scale_color_manual(values = c("blue", "red"))
  
  # Boxplot comparison
  p3 <- ggplot(plot_data, aes(x = treatment, y = ps, fill = treatment)) +
    geom_boxplot(alpha = 0.6) +
    geom_jitter(width = 0.1, alpha = 0.2, size = 0.5) +
    labs(title = paste("Distribution Comparison - Imputation", i),
         x = "Treatment Group",
         y = "Propensity Score") +
    theme_minimal() +
    scale_fill_manual(values = c("blue", "red"))
  
  # Arrange plots
  grid.arrange(p1, p2, p3, ncol = 3)
}
```

## Weight Distribution

```{r weight-distribution}
# Summarize weight distributions for twang
weight_summary <- data.frame()

for (i in 1:n_imputations) {
  weights <- twang_results[[i]]$weights
  treated <- imputed_datasets[[i]]$ever_lapse_binary == 1
  
  summary_row <- data.frame(
    Imputation = i,
    Mean_Weight_Control = mean(weights[!treated]),
    SD_Weight_Control = sd(weights[!treated]),
    Min_Weight_Control = min(weights[!treated]),
    Max_Weight_Control = max(weights[!treated]),
    Mean_Weight_Treated = mean(weights[treated]),
    SD_Weight_Treated = sd(weights[treated]),
    Min_Weight_Treated = min(weights[treated]),
    Max_Weight_Treated = max(weights[treated])
  )
  
  weight_summary <- rbind(weight_summary, summary_row)
}

# Average across imputations
weight_summary_avg <- weight_summary |>
  summarise(
    Mean_Weight_Control = mean(Mean_Weight_Control),
    SD_Weight_Control = mean(SD_Weight_Control),
    Min_Weight_Control = mean(Min_Weight_Control),
    Max_Weight_Control = mean(Max_Weight_Control),
    Mean_Weight_Treated = mean(Mean_Weight_Treated),
    SD_Weight_Treated = mean(SD_Weight_Treated),
    Min_Weight_Treated = mean(Min_Weight_Treated),
    Max_Weight_Treated = mean(Max_Weight_Treated)
  )

message("\nTwang Weight Distribution Summary:")
kable(weight_summary,
      caption = "Weight distributions by imputation",
      digits = 3)

message("\nAverage across all imputations:")
kable(weight_summary_avg,
      caption = "Average weight distributions across imputed datasets",
      digits = 3)

# Check for extreme weights
max_weight <- max(weight_summary$Max_Weight_Control, weight_summary$Max_Weight_Treated)
if (max_weight > 10) {
  message("\n⚠ Warning: Maximum weight exceeds 10, indicating potential instability")
} else if (max_weight > 5) {
  message("\nNote: Some weights exceed 5, monitor for potential instability")
} else {
  message("\n✓ All weights are within reasonable range (<5)")
}
```

## Save Propensity Score Results

```{r save-results}
# Save twang PS results for use in outcome analysis
ps_output <- list(
  twang_results = twang_results,
  balance_summary = balance_summary_all,
  avg_balance = avg_balance,
  weight_summary = weight_summary_avg,
  formula_used = ps_formula,
  n_imputations = n_imputations,
  method = "twang_gbm",
  n_trees = n_trees,
  analysis_mode = analysis_mode
)

saveRDS(ps_output, file.path(reanalysis_data_dir, "ps_results_twang.rds"))

message("\nTwang propensity score results saved to: ", 
        file.path(reanalysis_data_dir, "ps_results_twang.rds"))
```

## Summary

```{r summary}
# Final summary
message("\n=== TWANG PROPENSITY SCORE ANALYSIS SUMMARY ===")
message("Method: Generalized Boosted Models (GBM) via twang")
message("Imputations processed: ", n_imputations)
message("Analysis mode: ", analysis_mode)
message("Trees used: ", n_trees)
message("Estimand: ATT (Average Treatment Effect on the Treated)")
message("Stop method: es.mean (effect size minimization)")

# Enhanced formula summary
message("\nEnhanced formula included:")
message("  - DR severity (person_dr)")
message("  - Treatment type")
message("  - All standard covariates from original analysis")

# Balance summary
message("\nBalance achieved (averaged across imputations):")
message("  - Mean effect size: ", round(avg_balance$Mean_ES, 3))
message("  - Max effect size: ", round(avg_balance$Max_ES, 3))
message("  - Variables with |ES| > 0.1: ", round(avg_balance$N_Imbalanced, 1))
message("  - Mean KS statistic: ", round(avg_balance$Mean_KS, 3))
message("  - Max KS statistic: ", round(avg_balance$Max_KS, 3))

# Balance assessment
if (avg_balance$Max_ES > 0.25) {
  message("\n⚠ Warning: Maximum effect size > 0.25, indicating potential residual imbalance")
  message("  Consider increasing n.trees or adjusting twang parameters")
} else if (avg_balance$Max_ES > 0.1) {
  message("\nNote: Some covariates have effect size > 0.1")
  message("  This is acceptable but monitor in outcome analysis")
} else {
  message("\n✓ Excellent balance achieved (all effect sizes < 0.1)")
}

# Weight stability
message("\nWeight stability:")
message("  - Max weight (control): ", round(weight_summary_avg$Max_Weight_Control, 2))
message("  - Max weight (treated): ", round(weight_summary_avg$Max_Weight_Treated, 2))
```

## Next Steps

1. **Outcome Analysis** (`reanalysis-4-outcome_analysis.qmd`):
   - Apply weights to outcome models
   - Estimate treatment effects for each imputation
   - Pool results using Rubin's rules
   
2. **Sensitivity Analysis** (`reanalysis-5-sensitivity.qmd`):
   - Compare different PS methods
   - Assess robustness to model specification