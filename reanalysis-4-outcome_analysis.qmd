---
title: "Reanalysis Step 4: Main Effects Outcome Analysis"
subtitle: "Analyzing lapse effect without interactions"
author: "Erik Westlund"
date: "`r Sys.Date()`"
format: 
  html:
    toc: true
    toc-depth: 3
---

## Setup

```{r setup}
#| include: false
source("dependencies.R")
source("functions.R")  # Load formula definitions and helper functions
setup_analysis(seed = 2025)

library(mice)
library(survey)
library(broom)
library(marginaleffects)
library(emmeans)
library(tidyr)
library(ggplot2)

# ANALYSIS MODE: Use same as imputation
analysis_mode <- "final"  # Should match imputation mode

# Check for required files
required_files <- c(
  "imputed_datasets.rds",
  "twang_weights.rds",
  "variable_lists.rds"
)

missing_files <- c()
for (file in required_files) {
  if (!file.exists(file.path(reanalysis_data_dir, file))) {
    missing_files <- c(missing_files, file)
  }
}

if (length(missing_files) > 0) {
  stop(paste("Required files not found. Please run previous steps first:\n",
             "- Step 2 (Multiple Imputation) creates: imputed_datasets.rds\n",
             "- Step 3 (Propensity Scores) creates: twang_weights.rds\n",
             "Missing files:", paste(missing_files, collapse = ", ")))
}

# Initialize logging
log_file <- init_log("outcome_analysis")

# Load data and weights
log_message("Loading imputed datasets and weights")
imputed_datasets <- readRDS(file.path(reanalysis_data_dir, "imputed_datasets.rds"))
twang_weights <- readRDS(file.path(reanalysis_data_dir, "twang_weights.rds"))

# Determine number of imputations to use based on analysis mode
n_imputations_available <- length(imputed_datasets)
if (analysis_mode == "test") {
  n_imputations <- min(2, n_imputations_available)  # Use only 2 for testing
  # Subset to first 2 imputations for testing
  imputed_datasets <- imputed_datasets[1:n_imputations]
  twang_weights <- twang_weights[1:n_imputations]
} else {
  n_imputations <- n_imputations_available  # Use all available
}

# Load variable lists
variable_lists <- readRDS(file.path(reanalysis_data_dir, "variable_lists.rds"))
```

**Analysis Parameters:**
- Mode: `r analysis_mode`
- Number of imputations: `r n_imputations` `r if(analysis_mode == "test") paste0("(", n_imputations_available, " available, using first ", n_imputations, " for testing)") else ""`
- Estimand: ATT (Average Treatment Effect in the Treated)

## Data Overview

```{r data-overview}
# First imputed dataset summary
first_imp <- imputed_datasets[[1]]

# Add weights to the first dataset
first_imp$weights <- twang_weights[[1]]

# Sample sizes
n_total <- nrow(first_imp)
n_lapsed <- sum(first_imp$ever_lapse_binary == 1)
n_control <- sum(first_imp$ever_lapse_binary == 0)

# Outcome summary
n_vi <- sum(first_imp$outcome_va_vi_binary == 1)
prop_vi <- mean(first_imp$outcome_va_vi_binary == 1) * 100

summary_df <- data.frame(
  Measure = c("Total patients", "Lapsed", "Not lapsed", 
              "VI outcomes", "VI proportion"),
  Value = c(n_total, n_lapsed, n_control, n_vi, paste0(round(prop_vi, 1), "%"))
)

kable(summary_df)
```

### Variable Distributions in First Imputed Dataset

**DR Severity:**
```{r dr-severity-dist}
dr_table <- table(first_imp$dr_severity)
dr_df <- data.frame(
  Category = names(dr_table),
  Count = as.numeric(dr_table),
  Percentage = paste0(round(100 * as.numeric(dr_table) / sum(dr_table), 1), "%")
)
kable(dr_df, align = c('l', 'r', 'r'))
```

**Lapse Status:**
```{r lapse-dist}
lapse_table <- table(first_imp$ever_lapse_binary)
lapse_df <- data.frame(
  Lapse_Status = c("No Lapse", "Lapsed"),
  Count = as.numeric(lapse_table),
  Percentage = paste0(round(100 * as.numeric(lapse_table) / sum(lapse_table), 1), "%")
)
kable(lapse_df, align = c('l', 'r', 'r'))
```

## Define Model Formula

```{r define-formula}
# Get the ORIGINAL formulas from functions.R
# Using original to maintain consistency with submitted analysis
original_formulas <- get_analysis_formulas()

# Use the full formula (without dr_severity)
main_effects_formula <- original_formulas$full
```

### Model Specification

**Formula:**
```{r show-formula}
print(main_effects_formula)
```

**Model Structure:**
- Main effect of interest: `ever_lapse_binary`
- Adjustment variables: DR severity, treatment status, and baseline covariates
- No interaction terms

## Fit Models to Each Imputed Dataset

```{r fit-models}
# Check if models are already cached
models_cache_file <- file.path(reanalysis_data_dir, "fitted_models_main_effects.rds")
force_refit <- FALSE  # Set to TRUE if you want to force re-fitting

if (file.exists(models_cache_file) && !force_refit) {
  # Load cached models
  cached_models <- readRDS(models_cache_file)
  fitted_models <- cached_models$fitted_models
  model_summaries <- cached_models$model_summaries
  models_loaded_from_cache <- TRUE
  cache_location <- models_cache_file
} else {
  # Fit new models
  models_loaded_from_cache <- FALSE
  
  # Store fitted models and extracted coefficients
  fitted_models <- list()
  model_summaries <- list()
  
  log_message(paste0("Starting model fitting for ", n_imputations, " imputations"))
  
  for (i in 1:n_imputations) {
    log_progress(i, n_imputations, "Model")
    
    # Get dataset and weights
    imp_data <- imputed_datasets[[i]]
    imp_data$weights <- twang_weights[[i]]
    
    # Create survey design object for weighted analysis
    design <- svydesign(
      ids = ~ e_mrn_deidentified,
      weights = ~ weights,
      data = imp_data
    )
    
    # Fit weighted logistic regression - MAIN EFFECTS ONLY
    model <- svyglm(
      main_effects_formula,
      design = design,
      family = quasibinomial()
    )
    
    # Store model
    fitted_models[[i]] <- model
    
    # Extract and store summary
    model_summaries[[i]] <- tidy(model, conf.int = TRUE)
  }
  
  # Save to cache
  cached_models <- list(
    fitted_models = fitted_models,
    model_summaries = model_summaries,
    formula_used = main_effects_formula,
    n_imputations = n_imputations,
    timestamp = Sys.time()
  )
  
  saveRDS(cached_models, models_cache_file)
  cache_location <- models_cache_file
}
```

**Models cache status:** `r ifelse(models_loaded_from_cache, paste("Loaded from", cache_location), paste("Newly fitted and saved to", cache_location))`

### Example Model Summary (First Imputation)

```{r model-summary-display}
kable(model_summaries[[1]] |> 
      select(term, estimate, std.error, p.value) |> 
      head(10),
      caption = "First 10 coefficients from imputation 1")
```

## Pool Results Across Imputations

```{r pool-results}
# Create a proper mira object for mice pooling
# The key is to create a list with the correct structure
mira_object <- list(
  call = fitted_models[[1]]$call,
  call1 = fitted_models[[1]]$call,
  nmis = rep(1, n_imputations),  # Placeholder
  analyses = fitted_models
)
class(mira_object) <- "mira"

# Now pool using mice's native function
pooled <- pool(mira_object)

# Get pooled results with confidence intervals
pooled_results <- summary(pooled, conf.int = TRUE) |> 
  as.data.frame()

# Extract main effect of lapse
lapse_effect <- pooled_results[pooled_results$term == "ever_lapse_binary", ]

# Calculate OR and CI
lapse_effect$OR <- exp(lapse_effect$estimate)
lapse_effect$OR_lower <- exp(lapse_effect$`2.5 %`)
lapse_effect$OR_upper <- exp(lapse_effect$`97.5 %`)

# Format for display
main_effect_summary <- data.frame(
  Effect = "Lapsing from care",
  Log_Odds = round(lapse_effect$estimate, 4),
  SE = round(lapse_effect$std.error, 4),
  OR = round(lapse_effect$OR, 3),
  CI_Lower = round(lapse_effect$OR_lower, 3),
  CI_Upper = round(lapse_effect$OR_upper, 3),
  P_Value = format.pval(lapse_effect$p.value, digits = 4, eps = 0.0001)
)

kable(main_effect_summary, 
      caption = "Main effect of lapsing on vision impairment/blindness")
```

### Pooling Diagnostics

```{r pooling-diagnostics}
# Check if fmi column exists, otherwise calculate it
if ("fmi" %in% names(lapse_effect)) {
  fmi_value <- lapse_effect$fmi
} else if ("lambda" %in% names(lapse_effect)) {
  fmi_value <- lapse_effect$lambda
} else {
  # If no FMI available, set to NA
  fmi_value <- NA
}

# Create diagnostics table
pool_diag <- data.frame(
  Metric = c("Number of imputations", 
             "Number of parameters",
             "Average degrees of freedom"),
  Value = c(n_imputations,
            nrow(pooled_results),
            ifelse("df" %in% names(pooled_results),
             round(mean(pooled_results$df, na.rm = TRUE), 1), NA))
)

kable(pool_diag, caption = "Pooling diagnostics for main effect model")

# Extract lapse coefficient from each imputation
imputation_estimates <- data.frame(
  imputation = 1:n_imputations,
  log_odds = numeric(n_imputations),
  OR = numeric(n_imputations),
  stringsAsFactors = FALSE
)

# Get the lapse coefficient from each model
for (i in 1:n_imputations) {
  # Extract from model summaries
  lapse_row <- model_summaries[[i]][model_summaries[[i]]$term == "ever_lapse_binary", ]
  
  if (nrow(lapse_row) > 0) {
    imputation_estimates$log_odds[i] <- lapse_row$estimate
    imputation_estimates$OR[i] <- exp(lapse_row$estimate)
  }
}

# Calculate running average
imputation_estimates$running_avg_OR <- cumsum(imputation_estimates$OR) / seq_along(imputation_estimates$OR)

# Display the convergence table (first 10 and last 10 if more than 20)
if (n_imputations > 20) {
  convergence_display <- rbind(
    head(imputation_estimates, 10),
    data.frame(imputation = "...", log_odds = "...", OR = "...", running_avg_OR = "..."),
    tail(imputation_estimates, 10)
  )
} else {
  convergence_display <- imputation_estimates
}

# Format for display
convergence_display_formatted <- convergence_display
if (is.numeric(convergence_display$OR)) {
  convergence_display_formatted$OR <- round(convergence_display$OR, 4)
  convergence_display_formatted$running_avg_OR <- round(convergence_display$running_avg_OR, 4)
  convergence_display_formatted$log_odds <- round(convergence_display$log_odds, 4)
}

kable(convergence_display_formatted,
      caption = "Lapse effect estimates by imputation with running average",
      col.names = c("Imputation", "Log Odds", "OR", "Running Average OR"))
```

### Pooling Convergence Visualization

```{r convergence-plot}
#| fig-height: 6
#| fig-width: 10

# Create the convergence plot
convergence_plot <- ggplot(imputation_estimates, aes(x = imputation)) +
  # Individual OR estimates as points
  geom_point(aes(y = OR), color = "#2E86AB", size = 2, alpha = 0.6) +
  
  # Running average as a line
  geom_line(aes(y = running_avg_OR), color = "#D62728", size = 1.2) +
  
  # Add a horizontal line at the final pooled estimate
  geom_hline(yintercept = tail(imputation_estimates$running_avg_OR, 1), 
             linetype = "dashed", color = "#D62728", alpha = 0.5) +
  
  # Labels and theme
  labs(
    title = "Convergence of Pooled Estimate Across Imputations",
    subtitle = "Blue points = individual imputation OR, Red line = running average",
    x = "Imputation Number",
    y = "Odds Ratio",
    caption = paste0("Final pooled OR: ", round(tail(imputation_estimates$running_avg_OR, 1), 3))
  ) +
  
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 11),
    axis.text = element_text(size = 10),
    axis.title = element_text(size = 11),
    plot.caption = element_text(size = 9, hjust = 0.5)
  ) +
  
  # Make x-axis show only integers
  scale_x_continuous(breaks = function(x) {
    seq(from = ceiling(x[1]), to = floor(x[2]), by = max(1, floor((x[2] - x[1]) / 10)))
  }) +
  
  # Set reasonable y-axis limits
  coord_cartesian(ylim = c(
    min(imputation_estimates$OR) * 0.95,
    max(imputation_estimates$OR) * 1.05
  ))

print(convergence_plot)

# Calculate and display convergence statistics
convergence_stats <- data.frame(
  Metric = c(
    "Mean OR across imputations",
    "SD of OR across imputations", 
    "CV of OR (%)",
    "Range of OR",
    "Final running average"
  ),
  Value = c(
    round(mean(imputation_estimates$OR), 4),
    round(sd(imputation_estimates$OR), 4),
    round(100 * sd(imputation_estimates$OR) / mean(imputation_estimates$OR), 2),
    paste0("[", round(min(imputation_estimates$OR), 4), ", ", 
           round(max(imputation_estimates$OR), 4), "]"),
    round(tail(imputation_estimates$running_avg_OR, 1), 4)
  )
)

kable(convergence_stats, caption = "Convergence statistics for lapse effect")
```

## Full Model Results

```{r full-results}
# Format all pooled results
pooled_results$OR <- exp(pooled_results$estimate)
pooled_results$OR_lower <- exp(pooled_results$`2.5 %`)
pooled_results$OR_upper <- exp(pooled_results$`97.5 %`)

# Create clean results table
full_results <- pooled_results |>
  select(term, estimate, std.error, OR, OR_lower, OR_upper, p.value) |>
  mutate(
    estimate = round(estimate, 4),
    std.error = round(std.error, 4),
    OR = round(OR, 3),
    OR_lower = round(OR_lower, 3),
    OR_upper = round(OR_upper, 3),
    p.value = format.pval(p.value, digits = 4, eps = 0.0001)
  ) |>
  rename(
    Variable = term,
    `Log Odds` = estimate,
    SE = std.error,
    `OR (95% CI)` = OR,
    `CI Lower` = OR_lower,
    `CI Upper` = OR_upper,
    `P-value` = p.value
  )

# Display key variables
key_vars <- c("ever_lapse_binary")
key_results <- full_results[full_results$Variable %in% key_vars, ]

kable(key_results, 
      caption = "Final results for lapsing from care")
```

## Average Marginal Effects

```{r marginal-effects}
# Check if AMEs are cached
ame_cache_file <- file.path(reanalysis_data_dir, "ame_results_main_effects.rds")
force_recalc_ame <- FALSE  # Set to TRUE to force recalculation

if (file.exists(ame_cache_file) && !force_recalc_ame) {
  # Load cached AMEs
  ame_cache <- readRDS(ame_cache_file)
  ame_list <- ame_cache$ame_list
  ame_loaded_from_cache <- TRUE
  ame_cache_location <- ame_cache_file
} else {
  # Calculate AME for each imputed dataset then pool
  ame_loaded_from_cache <- FALSE
  ame_list <- list()
  
  # Initialize progress tracking
  progress <- init_progress(n_imputations, "Calculating AMEs")
  
  for (i in 1:n_imputations) {
    # Update progress
    progress <- update_progress(progress)
    
    imp_data <- imputed_datasets[[i]]
    imp_data$weights <- twang_weights[[i]]
    
    # Calculate AME with clustering and weights
    # marginaleffects handles survey designs well
    ame <- avg_slopes(
      fitted_models[[i]], 
      variables = "ever_lapse_binary",
      newdata = imp_data,
      vcov = ~e_mrn_deidentified,  # Cluster SEs on patient ID
      wts = imp_data$weights  # Apply PS weights
    )
    
    ame_list[[i]] <- ame
  }
  
  # Save to cache
  ame_cache <- list(
    ame_list = ame_list,
    n_imputations = n_imputations,
    timestamp = Sys.time()
  )
  saveRDS(ame_cache, ame_cache_file)
  ame_cache_location <- ame_cache_file
}

# Extract estimates and SEs for pooling
ame_estimates <- sapply(ame_list, function(x) x$estimate)
ame_ses <- sapply(ame_list, function(x) x$std.error)

# Apply Rubin's rules for pooling
pooled_ame_est <- mean(ame_estimates)
within_var <- mean(ame_ses^2)
between_var <- var(ame_estimates)
total_var <- within_var + between_var * (1 + 1/n_imputations)
pooled_ame_se <- sqrt(total_var)

# Calculate FMI and df
fmi <- (between_var * (1 + 1/n_imputations)) / total_var
df_ame <- (n_imputations - 1) / fmi^2

# CI using t-distribution
t_crit <- qt(0.975, df_ame)
ci_lower <- pooled_ame_est - t_crit * pooled_ame_se
ci_upper <- pooled_ame_est + t_crit * pooled_ame_se

pooled_ame <- data.frame(
  Effect = "Average Marginal Effect of Lapse",
  AME = pooled_ame_est,
  SE = pooled_ame_se,
  CI_Lower = ci_lower,
  CI_Upper = ci_upper,
  FMI = fmi,
  Interpretation = paste0(
    "On average, lapsing from care increases the probability of VI/blindness by ",
    round(pooled_ame_est, 3)
  )
)

kable(pooled_ame |> select(-Interpretation), 
      caption = "Average marginal effect of lapsing",
      digits = 4)

# Display interpretation separately
ame_text <- pooled_ame$Interpretation
```

**AME cache status:** `r ifelse(ame_loaded_from_cache, paste("Loaded from", ame_cache_location), paste("Newly calculated and saved to", ame_cache_location))`

`r ame_text`

## Predicted Probabilities

```{r predicted-probs}
# Use emmeans for predicted probabilities
# We'll use the first imputed model for illustration

# Get the data from the first imputation
imp_data <- imputed_datasets[[1]]
imp_data$weights <- twang_weights[[1]]

# Set emmeans options to handle larger reference grids
emm_options(rg.limit = 50000)

# Get estimated marginal means for the main effect of lapse
# Provide the data explicitly for survey models
emm_results <- tryCatch({
  emmeans(fitted_models[[1]], 
          ~ ever_lapse_binary,
          data = imp_data,  # Explicitly provide data
          type = "response",  # Get probabilities not log-odds
          weights = "proportional")  # Use observed proportions
}, error = function(e) {
  # If emmeans fails, return NULL and explain
  warning("Could not calculate emmeans: ", e$message)
  NULL
})

# Display results if emmeans worked
if (!is.null(emm_results)) {
  pred_df <- as.data.frame(emm_results)
  
  # Clean up column names
  if ("prob" %in% names(pred_df)) {
    pred_df$Predicted_Prob <- round(pred_df$prob, 3)
  } else if ("response" %in% names(pred_df)) {
    pred_df$Predicted_Prob <- round(pred_df$response, 3)
  } else if ("emmean" %in% names(pred_df)) {
    # If we're on the link scale, transform to probability
    pred_df$Predicted_Prob <- round(plogis(pred_df$emmean), 3)
  }
  
  # Create lapse labels
  pred_df$Lapse_Status <- ifelse(pred_df$ever_lapse_binary == 1, "Lapsed", "Not Lapsed")
  
  # Display predictions
  kable(pred_df |> select(Lapse_Status, Predicted_Prob, SE, lower.CL, upper.CL), 
        caption = "Predicted probability of VI/blindness by lapse status (marginalized over all covariates)",
        col.names = c("Lapse Status", "Predicted Probability", "SE", "Lower CI", "Upper CI"),
        digits = 3)
  
  # Calculate and display the contrast (risk difference)
  contrasts_lapse <- pairs(emm_results)
  contrasts_df <- as.data.frame(contrasts_lapse)
  
  kable(contrasts_df |> 
        mutate(
          Contrast = "Lapsed - Not Lapsed",
          Risk_Difference = round(estimate, 3),
          SE = round(SE, 4),
          CI_Lower = round(lower.CL, 3),
          CI_Upper = round(upper.CL, 3),
          p.value = format.pval(p.value, digits = 4, eps = 0.0001)
        ) |>
        select(Contrast, Risk_Difference, SE, CI_Lower, CI_Upper, p.value),
        caption = "Main effect: Risk difference with proper variance estimation",
        col.names = c("Contrast", "Risk Difference", "SE", "Lower CI", "Upper CI", "P-value"))
} else {
  # If emmeans failed, display message
  print("Note: Predicted probabilities could not be calculated using emmeans.")
  print("The main analysis results (pooled coefficients and AMEs) above remain valid.")
}
```

## Save Results

```{r save-results}
# Save key results for reporting
results_to_save <- list(
  main_effect = main_effect_summary,
  pooled_coefficients = pooled_results,
  full_results = full_results,
  ame_results = pooled_ame,
  predicted_probabilities = pred_wide,
  model_formula = main_effects_formula,
  n_imputations = n_imputations,
  analysis_mode = analysis_mode,
  timestamp = Sys.time()
)

saveRDS(results_to_save, 
        file.path(reanalysis_data_dir, "outcome_analysis_main_effects_results.rds"))

save_location <- file.path(reanalysis_data_dir, "outcome_analysis_main_effects_results.rds")
```

**Results saved to:** `r save_location`

## Summary

The main effects model shows:

- **Primary finding**: Lapsing from care has a significant effect on vision impairment/blindness (OR = `r round(lapse_effect$OR, 2)`, p `r ifelse(lapse_effect$p.value < 0.001, "< 0.001", paste("=", round(lapse_effect$p.value, 3)))`)
- **Effect size**: The average marginal effect indicates that lapsing increases the probability of VI/blindness by `r round(pooled_ame_est, 3)`

```{r finalize-log}
# Finalize logging
log_message("Outcome analysis completed successfully")
final_log <- finalize_log(success = TRUE)
```

**Log file:** `r final_log`
